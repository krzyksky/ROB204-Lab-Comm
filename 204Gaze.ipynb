{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38048db9",
   "metadata": {},
   "source": [
    "# ROB 204 - Gaze Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "754a23db-578f-42d7-8a4a-45f0f3f99c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "from picamera2 import Picamera2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython import display\n",
    "import os, sys, math, threading, time, logging\n",
    "from gpiozero import AngularServo as Servo\n",
    "from gpiozero.pins.pigpio import PiGPIOFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178c007c-af9a-4f5f-b64b-697080c803f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "pigpio_factory = PiGPIOFactory()\n",
    "EmbodimentPitchServo = Servo(18, pin_factory=pigpio_factory, min_angle = 80, max_angle = -100, min_pulse_width=0.0005, max_pulse_width=0.0024)\n",
    "EmbodimentYawServo = Servo(13, pin_factory=pigpio_factory, min_angle = 80, max_angle = -100, min_pulse_width=0.0005, max_pulse_width=0.0024)\n",
    "\n",
    "def setEmbodimentPitch(degrees):\n",
    "    global EmbodimentPitchServo\n",
    "    EmbodimentPitchServo.angle = (degrees)\n",
    "\n",
    "def setEmbodimentYaw(degrees):\n",
    "    global EmbodimentYawServo\n",
    "    EmbodimentYawServo.angle = (degrees)\n",
    "\n",
    "setEmbodimentPitch(0)\n",
    "setEmbodimentYaw(0)\n",
    "    \n",
    "# FUNCTION GENERATED WITH CHATGPT -- REVISE!!!\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d4f855-e3c9-4b83-8d5b-b0d7c3053567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rotation(yaw):\n",
    "    global tracking_output\n",
    "    if yaw > 20:\n",
    "        tracking_output.value = \"ðŸ‘ˆ\"\n",
    "        setEmbodimentYaw(-45)\n",
    "    elif yaw < -20:\n",
    "        tracking_output.value = \"ðŸ‘‰\"\n",
    "        setEmbodimentYaw(45)\n",
    "    else:\n",
    "        tracking_output.value = \"ðŸ«µ\"\n",
    "        setEmbodimentYaw(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eccb59f-01b8-4276-9c50-3fdbb4d4049c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1721335377.588044    4288 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1721335377.614347    4327 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1721335377.662987    4327 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5495dab9009241d18c24a3b7e6c50020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Start Tracking', style=ButtonStyle()â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f28a3aaf4d4a0eb156cc7f7e897fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"LIBCAMERA_LOG_LEVELS\"] = \"3\"\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=False,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "tracking = None\n",
    "tracking_run = False\n",
    "\n",
    "tracking_status = widgets.HTML(value=\"Tracking not started\")\n",
    "\n",
    "file = open(\"images/placeholder.jpg\", \"rb\")\n",
    "image = file.read()\n",
    "tracking_image  = widgets.Image(value=image,format='jpeg',width=640,height=480)\n",
    "\n",
    "tracking_output = widgets.HTML(value=\"ðŸ™ˆ\")\n",
    "tracking_fps = widgets.HTML(value=\"FPS: 0\")\n",
    "\n",
    "disp_container = widgets.VBox([tracking_status, tracking_image, tracking_output, tracking_fps])\n",
    "output = widgets.Output()\n",
    "\n",
    "TARGET_FPS = 10\n",
    "\n",
    "def tracking_function(tracking_status, tracking_image, tracking_output, tracking_fps):\n",
    "    tracking_status.value = \"Tracking starting...\"\n",
    "    with Picamera2() as picam:\n",
    "        picam.configure(picam.create_video_configuration(main={\"format\": 'RGB888', \"size\": (1296, 730)}))\n",
    "        picam.start()\n",
    "        tracking_status.value = \"Tracking started.\"\n",
    "        while tracking_run:\n",
    "            start_time = time.time()\n",
    "            image = picam.capture_array(\"main\")\n",
    "    \n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "            detection_result = detector.detect(mp_image)\n",
    "\n",
    "            resize_image = cv2.flip(image, 1)\n",
    "            resize_frame = cv2.resize(resize_image, (0, 0), fx = 0.25, fy = 0.25)\n",
    "            _,ret_array = cv2.imencode('.jpg', resize_frame)\n",
    "            tracking_image.value = ret_array\n",
    "            \n",
    "            try:\n",
    "                transformation_matrix = detection_result.facial_transformation_matrixes[0]\n",
    "                rotation_angles = rotation_matrix_to_euler_angles(transformation_matrix)\n",
    "                yaw_angle = np.degrees(rotation_angles[1])     \n",
    "                process_rotation(yaw_angle)\n",
    "    \n",
    "            except Exception as e:\n",
    "                tracking_output.value = \"ðŸ™ˆ\"\n",
    "                pass\n",
    "\n",
    "            fps = 1.0 / (time.time() - start_time)\n",
    "            tracking_fps.value = \"FPS: \" + str(fps)\n",
    "            sleep_time = (1.0 / TARGET_FPS) - (time.time() - start_time)\n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "            adj_fps = 1.0 / (time.time() - start_time)\n",
    "            tracking_fps.value = \"FPS: \" + str(adj_fps)\n",
    "\n",
    "def start_tracking(b):\n",
    "    global tracking, tracking_run, disp_container\n",
    "    with output:\n",
    "        if tracking is None or not tracking.is_alive():\n",
    "            tracking_run = True\n",
    "            tracking = threading.Thread(target=tracking_function, args=(tracking_status, tracking_image, tracking_output, tracking_fps, ))\n",
    "            tracking.start()\n",
    "\n",
    "def stop_tracking(b):\n",
    "    global tracking, tracking_run\n",
    "    with output:\n",
    "        if tracking is not None and tracking.is_alive():\n",
    "            tracking_run = False\n",
    "            tracking_status.value = \"Tracking stopped.\"\n",
    "\n",
    "\n",
    "start_btn = widgets.Button(description=\"Start Tracking\", button_style='success')\n",
    "start_btn.on_click(start_tracking)\n",
    "\n",
    "stop_btn = widgets.Button(description=\"Stop Tracking\", button_style='danger')\n",
    "stop_btn.on_click(stop_tracking)\n",
    "\n",
    "toolbar = widgets.HBox([start_btn, stop_btn])\n",
    "\n",
    "display.display(widgets.VBox([toolbar, disp_container]), output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
