{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38048db9",
   "metadata": {},
   "source": [
    "# ROB 204 - Gaze Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eccb59f-01b8-4276-9c50-3fdbb4d4049c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1721313324.946519    3136 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1721313324.954366    3369 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1721313324.973469    3371 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa8d2a8eade402c971d930f000e51f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Start Tracking', style=ButtonStyle()â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef5ef83280c48e791cae81289b99209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from picamera2 import Picamera2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import threading\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import time\n",
    "import sys, math\n",
    "\n",
    "# FUNCTION GENERATED WITH CHATGPT -- REVISE!!!\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=False,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "tracking = None\n",
    "tracking_run = False\n",
    "\n",
    "tracking_status = widgets.HTML(value=\"Tracking not started\")\n",
    "\n",
    "file = open(\"images/placeholder.jpg\", \"rb\")\n",
    "image = file.read()\n",
    "tracking_image  = widgets.Image(value=image,format='jpeg',width=640,height=480)\n",
    "\n",
    "tracking_output = widgets.HTML(value=\"ðŸ™ˆ\")\n",
    "tracking_fps = widgets.HTML(value=\"FPS: 0\")\n",
    "\n",
    "disp_container = widgets.VBox([tracking_status, tracking_image, tracking_output, tracking_fps])\n",
    "output = widgets.Output()\n",
    "\n",
    "def tracking_function(tracking_status, tracking_image, tracking_output, tracking_fps):\n",
    "    tracking_status.value = \"Tracking starting...\"\n",
    "    with Picamera2() as picam:\n",
    "        picam.configure(picam.create_video_configuration(main={\"format\": 'RGB888', \"size\": (1280, 720)}))\n",
    "        picam.start()\n",
    "        tracking_status.value = \"Tracking started.\"\n",
    "        while tracking_run:\n",
    "            start_time = time.time()\n",
    "            image = picam.capture_array(\"main\")\n",
    "            image = cv2.flip(image, 1)\n",
    "    \n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "            detection_result = detector.detect(mp_image)\n",
    "\n",
    "            resize_frame = cv2.resize(image, (0, 0), fx = 0.25, fy = 0.25)\n",
    "            resize_frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            _,ret_array = cv2.imencode('.jpg', resize_frame)\n",
    "            tracking_image.value = ret_array\n",
    "            \n",
    "            try:\n",
    "                transformation_matrix = detection_result.facial_transformation_matrixes[0]\n",
    "                rotation_angles = rotation_matrix_to_euler_angles(transformation_matrix)\n",
    "                yaw_angle = np.degrees(rotation_angles[1])\n",
    "                tracking_output.value = str(yaw_angle)\n",
    "    \n",
    "            except Exception as e:\n",
    "                tracking_output.value = \"ðŸ™ˆ\"\n",
    "                pass\n",
    "\n",
    "            tracking_fps.value = \"FPS: \" + str(1.0 / (time.time() - start_time))\n",
    "\n",
    "def start_tracking(b):\n",
    "    global tracking, tracking_run, disp_container\n",
    "    with output:\n",
    "        if tracking is None or not tracking.is_alive():\n",
    "            tracking_run = True\n",
    "            tracking = threading.Thread(target=tracking_function, args=(tracking_status, tracking_image, tracking_output, tracking_fps, ))\n",
    "            tracking.start()\n",
    "\n",
    "def stop_tracking(b):\n",
    "    global tracking, tracking_run\n",
    "    with output:\n",
    "        if tracking is not None and tracking.is_alive():\n",
    "            tracking_run = False\n",
    "            tracking_status.value = \"Tracking stopped.\"\n",
    "\n",
    "\n",
    "start_btn = widgets.Button(description=\"Start Tracking\", button_style='success')\n",
    "start_btn.on_click(start_tracking)\n",
    "\n",
    "stop_btn = widgets.Button(description=\"Stop Tracking\", button_style='danger')\n",
    "stop_btn.on_click(stop_tracking)\n",
    "\n",
    "toolbar = widgets.HBox([start_btn, stop_btn])\n",
    "\n",
    "display.display(widgets.VBox([toolbar, disp_container]), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a161b12-0827-4fcd-ba4d-dcb0d611b383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
